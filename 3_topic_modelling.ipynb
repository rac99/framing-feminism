{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling\n",
    "\n",
    "Now we get into the topic modelling, which will be using the LDA method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pre-processed csv file \n",
    "df = pd.read_csv('data/data_for_tm.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some filtering (if needed)\n",
    "\n",
    "We need to filter by decade now for each topic model, since we want to evaluate for a specific time frame \n",
    "\n",
    "we made three other separate files that filter based on year for topic modelling, since it usually takes a bit longer to run than the colocates (so we can run them concurrently)\n",
    "\n",
    "the filters for new york times and pittsburg gazette are also below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by decade \n",
    "# df = df.loc[df['year'] < 1990] # for 1980-1989\n",
    "# df = df.loc[(df['year'] > 1989) & (df['year'] < 2000)] # for 1990-1999\n",
    "# df = df.loc[(df['year'] > 1999) & (df['year'] < 2010)] # for 2000-2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by publisher (specifically NYT and pittsburg)\n",
    "# df = df.loc[df['publisher'] == 'The New York Times'] # 17833 articles \n",
    "# df = df.loc[df['publisher'] == 'Pittsburgh Post-Gazette (Pennsylvania)'] # 3229 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# change the cleaned text into a list\n",
    "data = df['clean_text'].values.tolist()\n",
    "\n",
    "# data_word lists \n",
    "data_words = [[word for word in simple_preprocess(str(doc))] for doc in data]\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "print(id2word)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "texts = data_words\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence Score\n",
    "\n",
    "So this next part is only run once to see what the coherence scores are based on different number of topics. It will help give us a better idea of what might be an ideal number of topics, though we would still need to manually verify and also play around with the number of topics. Based on both coherence store and qualitative observation of the granuarlity and coherence of individual topics, we can decide how many topics to proceed with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coherence score\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Compute coherence score\n",
    "\n",
    "# it would take forever to run each and every variation of topic number and find coherence score\n",
    "# so we have pre-selected certain topics numbers, with more on the lowerside, and segmenting as we go higher\n",
    "number_of_topics = 40 # [5,10,15,20,30,40,50]\n",
    "coherence_score = []\n",
    "# for i in number_of_topics:\n",
    "lda_model_c = LdaModel(corpus=corpus,\n",
    "                      id2word=id2word,\n",
    "                      alpha='auto', \n",
    "                      eta='auto', \n",
    "                      passes=10, \n",
    "                      iterations=50, \n",
    "                      random_state=42,\n",
    "                      num_topics=number_of_topics)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_c, \n",
    "                                      texts=texts, \n",
    "                                      dictionary=id2word, \n",
    "                                      coherence='c_v',\n",
    "                                      topn=30)\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "# number_of_topics.append(i)\n",
    "coherence_score.append(coherence_lda)\n",
    "\n",
    "# Create a dataframe of coherence score by number of topics \n",
    "topic_coherence = pd.DataFrame({'number_of_topics':number_of_topics,\n",
    "                                'coherence_score':coherence_score})\n",
    "\n",
    "# we have a table of the different coherence values\n",
    "topic_coherence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coherence scores:\n",
    "\n",
    "- 5 topics: 0.496398 (9 mins)\n",
    "- 20 topics: 0.604874 (11 mins)\n",
    "- 30 topics: 0.567641 (15 mins)\n",
    "- 40 topics: 0.543457 (31 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot these coherence scores\n",
    "topic_plot = topic_coherence.plot.line(x='number_of_topics', y='coherence_score')\n",
    "\n",
    "topic_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model\n",
    "\n",
    "Once we have decided above with a good number of topics, we can run the LDA model here below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "# Define the number of topics \n",
    "n_topics = 30\n",
    "\n",
    "# Run the LDA model\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                        id2word=id2word,\n",
    "                        alpha='auto', \n",
    "                        eta='auto', \n",
    "                        passes=10, \n",
    "                        iterations=500, \n",
    "                        random_state=42,\n",
    "                        num_topics=n_topics)\n",
    "\n",
    "print(\"lda_model finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of top 30 words with their probability weights\n",
    "print(\"lda_model, with top 30 words: \")\n",
    "for idx, topic in lda_model.print_topics(num_topics=n_topics, num_words=30):\n",
    "    print(\"Topic: {} Word: {}\".format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and enable notebook to run visualization\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    " \n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, \n",
    "                                     corpus, \n",
    "                                     dictionary=lda_model.id2word,\n",
    "                                     mds='mmds',\n",
    "                                     sort_topics=False)\n",
    "\n",
    "pyLDAvis.save_html(vis, 'lda_model_nyt_30_topics.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
