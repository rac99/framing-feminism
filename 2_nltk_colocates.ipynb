{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colocates\n",
    "\n",
    "It seems colocates can be spelled as co-locates, collocates, or colocates, so assume they are all the same. We used 'colocate' typically for the variable names and such.\n",
    "\n",
    "This is done using the nltk library, with some math behind what happens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pre-processed csv file \n",
    "df = pd.read_csv('data/data_for_cl.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering for our analysis\n",
    "Since we are doing analysis per decade, we have to filter out the years we want. This means that each time you run the file, you will have to double check which filter you want to apply \n",
    "\n",
    "we also filtered for two specific papers (Pittsburgh Post-Gazette (Pennsylvania), The New York Times) which is in the cell below the decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by decade \n",
    "# df = df.loc[df['year'] < 1990] # for 1980-1989\n",
    "# df = df.loc[(df['year'] > 1989) & (df['year'] < 2000)] # for 1990-1999\n",
    "# df = df.loc[(df['year'] > 1999) & (df['year'] < 2010)] # for 2000-2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by publisher (specifically NYT and pittsburg)\n",
    "df = df.loc[df['publisher'] == 'The New York Times'] # 17833 articles \n",
    "# df = df.loc[df['publisher'] == 'Pittsburgh Post-Gazette (Pennsylvania)'] # 3229 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# change the cleaned text into a list\n",
    "data = df['clean_text'].values.tolist()\n",
    "\n",
    "# data_word lists \n",
    "data_words = [[word for word in simple_preprocess(str(doc))] for doc in data]\n",
    "\n",
    "tokens = [i for j in data_words for i in j]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "\n",
    "word = 'feminism'\n",
    "\n",
    "dict_col = {}\n",
    "df_output_col = pd.DataFrame(columns=['word_of_interest', 'colocate', 'score'])\n",
    "\n",
    "# Ngrams with 'feminism' as a member\n",
    "word_filter = lambda *w: word not in w\n",
    "\n",
    "## Bigrams - takes around 2-3 minutes per word\n",
    "finder = BigramCollocationFinder.from_words(tokens)\n",
    "# only bigrams that appear 3+ times\n",
    "finder.apply_freq_filter(3)\n",
    "# only bigrams that contain word of interest\n",
    "finder.apply_ngram_filter(word_filter)\n",
    "# return the 20 n-grams with the highest likelihood ratio\n",
    "counter = 0 \n",
    "for i in finder.score_ngrams(bigram_measures.likelihood_ratio):\n",
    "    if counter < 20:\n",
    "        print(i)\n",
    "        df_output_col.loc[len(df_output_col.index)] = [word, i[0], i[1]] \n",
    "        counter += 1  \n",
    "# print(finder.nbest(bigram_measures.likelihood_ratio, 15),)\n",
    "# add it to a dictionary of lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output as a csv for future use \n",
    "df_output_col.to_csv(\"col_nyt_feminism.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
